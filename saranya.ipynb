{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model from the Saranya paper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "#NN\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# setting seed \n",
    "np.random.seed(seed=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "img_1 = cv2.imread(f\"seg_dataset_saranya2021/Green/{str(i)}.jpg\")\n",
    "img_2 = cv2.imread(\"seg_dataset_saranya2021/Overripen/2.jpg\")\n",
    "print(\"image 1 shape (lines, columns, channels) = \", img_1.shape) \n",
    "print(\"image 2 shape (lines, columns, channels) = \", img_2.shape) \n",
    "print(\"\\nimage type: \", type(img_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img_1 = cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB) # BGR to RGB \n",
    "rgb_img_2 = cv2.cvtColor(img_2, cv2.COLOR_BGR2RGB) # BGR to RGB \n",
    "plt.imshow(rgb_img_1)\n",
    "#plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(rgb_img_2)\n",
    "#plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset Saranya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to the image folders of each class\n",
    "class1_path = \"seg_dataset_saranya2021/Green\"\n",
    "class2_path = \"seg_dataset_saranya2021/Midripen\"\n",
    "class3_path = \"seg_dataset_saranya2021/Overripen\"\n",
    "class4_path = \"seg_dataset_saranya2021/Yellowish_Green\"\n",
    "\n",
    "# Define empty lists to store the images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Loop through each folder and extract the images\n",
    "for class_path, class_label in [(class1_path, 0), (class2_path, 1), (class3_path, 2), (class4_path, 3)]:\n",
    "    for image_file in os.listdir(class_path):\n",
    "        # Load the image and convert to RGB format\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (64, 64))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Add the image and label to the lists\n",
    "        images.append(image)\n",
    "        labels.append(class_label)\n",
    "\n",
    "# Convert the images and labels to NumPy arrays\n",
    "X = np.array(images)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(X[0], cv2.COLOR_HSV2RGB))\n",
    "#plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import Counter\n",
    "#print(sorted(Counter(y).items()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.4, \n",
    "                                                    shuffle= True,\n",
    "                                                    random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing data with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a vector with labels y, \n",
    "# returns the proper class weights \n",
    "# to be used in the fit function from keras\n",
    "# to use in the training of the model\n",
    "# prints the no. of classes\n",
    "\n",
    "# returned variable to be used in training keras model\n",
    "\n",
    "def get_weights(yy):\n",
    "    y=yy\n",
    "    # no. of elements per class\n",
    "    unique_classes, class_counts = np.unique(y, return_counts=True, axis=0)\n",
    "    print(f\"unique_classes-->{unique_classes}\")\n",
    "    # Print the unique classes and their corresponding counts\n",
    "    for cls, count in zip(unique_classes, class_counts):\n",
    "        print(f\"Class {cls}: {count} instances\")\n",
    "\n",
    "    total_instances = np.sum(class_counts)\n",
    "    class_weights = total_instances / (class_counts * len(unique_classes))\n",
    "\n",
    "    # Print the class weights\n",
    "    for cls, weight in zip(unique_classes, class_weights):\n",
    "        print(f\"Class {cls} weight: {weight}\")\n",
    "\n",
    "    class_weights /= np.sum(class_weights)\n",
    "\n",
    "    # Print the normalized class weights\n",
    "    for cls, weight in zip(unique_classes, class_weights):\n",
    "        print(f\"Class {cls} weight (normalized): {weight}\")\n",
    "\n",
    "\n",
    "    w_dict = {}\n",
    "    for i in range(len(unique_classes)):\n",
    "        w_dict[i] = class_weights[i]\n",
    "    \n",
    "    return w_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = get_weights(y_train)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = get_weights(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only applying data augmentation to the training data so that the model is not being evaluated on artifiacilly generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(20)\n",
    "a = [0, 0, 0, 0]\n",
    "np.allclose(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(X, y, num_augmented_samples = 100):\n",
    "    augmented_X = []\n",
    "    augmented_y = []\n",
    "\n",
    "    # Obtain the number of original samples\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    # Calculate the number of augmented samples needed for each class\n",
    "    unique_classes, label_counts = np.unique(y, return_counts=True, axis=0)\n",
    "    max_label_count = np.max(label_counts)\n",
    "\n",
    "    num_augmented_per_class = (max_label_count - label_counts) + num_augmented_samples # // num_augmented_samples\n",
    "\n",
    "    num_augmented_per_class = np.array(num_augmented_per_class, dtype=int)\n",
    "\n",
    "    while np.any(num_augmented_per_class):\n",
    "\n",
    "        ran = np.random.randint(num_samples)\n",
    "\n",
    "        image = X[ran]\n",
    "        label = y[ran]\n",
    "\n",
    "        if num_augmented_per_class[label] > 0:\n",
    "\n",
    "            flip = np.random.choice(['y', 'n'])\n",
    "\n",
    "            angle = np.random.uniform(-90, 90)\n",
    "            rotated_image = rotate_image(image, angle)\n",
    "\n",
    "            tx = np.random.randint(-10, 10)\n",
    "            ty = np.random.randint(-10, 10)\n",
    "            translated_image = translate_image(rotated_image, tx, ty)\n",
    "\n",
    "            brightness_factor = np.random.uniform(0.5, 1.3)\n",
    "            augmented_image = adjust_brightness(translated_image, brightness_factor)\n",
    "\n",
    "            if flip == 'y':\n",
    "                augmented_image = flip_image(augmented_image, flip_code=1)\n",
    "\n",
    "            #plt.imshow(cv2.cvtColor(augmented_image, cv2.COLOR_HSV2RGB))\n",
    "            #plt.show()\n",
    "\n",
    "            augmented_X.append(augmented_image)\n",
    "            augmented_y.append(label)\n",
    "\n",
    "            num_augmented_per_class[label] -= 1\n",
    "        \n",
    "    augmented_X = np.array(augmented_X)\n",
    "    augmented_y = np.array(augmented_y)\n",
    "\n",
    "    return np.append(X, augmented_X, axis=0), np.append(y, augmented_y, axis=0)\n",
    "\n",
    "def adjust_brightness(image, factor):\n",
    "    image = image.astype(np.float32)\n",
    "    image[:, :, 2] *= factor\n",
    "    image[:, :, 2] = np.clip(image[:, :, 2], 0, 255)\n",
    "    return image.astype(np.uint8)\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    height, width, _ = image.shape\n",
    "    center = (width // 2, height // 2)\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "    return rotated_image\n",
    "\n",
    "def flip_image(image, flip_code):\n",
    "    flipped_image = cv2.flip(image, flip_code)\n",
    "    return flipped_image\n",
    "\n",
    "def translate_image(image, tx, ty):\n",
    "    translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "    translated_image = cv2.warpAffine(image, translation_matrix, (image.shape[1], image.shape[0]))\n",
    "    return translated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug, y_aug = data_augmentation(X_train, y_train, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weights(y_aug)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing input data to improve training speed and OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_max = [179, 255, 255]\n",
    "\n",
    "X_aug_norm = np.divide(X_aug, hsv_max)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_aug_hot = to_categorical(y_aug)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# layers.Conv2D(# of filters, filter dimension, ...)\n",
    "# padding = 'valid' means no padding\n",
    "model.add(layers.Conv2D(32, 3, activation = 'relu', padding=\"valid\", input_shape = X[0].shape))\n",
    "model.add(layers.Conv2D(16, 5, activation = 'relu', strides=(1,1), padding=\"valid\"))\n",
    "model.add(layers.Conv2D(16, 5, activation = 'relu', padding=\"valid\"))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(16, 3, activation = 'relu', padding=\"valid\"))\n",
    "model.add(layers.Conv2D(16, 5, activation = 'relu', padding=\"valid\"))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units = 16, activation = 'relu'))\n",
    "model.add(layers.Dense(units = 4, activation = 'softmax'))\n",
    "\n",
    "opt_1 = keras.optimizers.Adam(learning_rate=0.005)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "callbacks, only using one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_early = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "cb_plateau = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.8,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.001,\n",
    "    cooldown=4,\n",
    "    min_lr=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = model.fit(X_aug_norm, y_aug_hot, validation_data=(X_test_norm, y_test_hot),# class_weight = w,\n",
    "               epochs=50, batch_size=16, callbacks=[cb_early, cb_plateau])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = np.divide(X_test, hsv_max)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "\n",
    "# best epoch obtained\n",
    "results_test = model.evaluate(X_test_norm, y_test_hot)\n",
    "print(results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of the model applied to the validation set\n",
    "y_preds = model.predict(X_test_norm)\n",
    "\n",
    "y_max = np.max(y_preds, axis=1)\n",
    "y_p = np.zeros(y_preds.shape)\n",
    "\n",
    "for i in range(y_p.shape[0]):\n",
    "    y_p[i, (np.where(y_preds[i]==np.max(y_preds[i])))] = 1\n",
    "\n",
    "#print(y_p)\n",
    "\n",
    "print(metrics.classification_report(y_test_hot, y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = bf.history['loss']\n",
    "val_loss = bf.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label = 'Training set')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation set')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = bf.history['accuracy']\n",
    "val_loss = bf.history['val_accuracy']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label = 'Training set')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation set')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"n_gen.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IST_PMBA23_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
