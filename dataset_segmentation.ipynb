{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import functions\n",
    "import os\n",
    "\n",
    "#for detection/segmentation\n",
    "!#pip install ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model = YOLO(\"yolov8l-seg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'source' is missing. Using 'source=https://ultralytics.com/images/bus.jpg'.\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 /Users/nunomachado/Documents/MECD/S2/PMBA/PMBA_project/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 2292.8ms\n",
      "Speed: 2.2ms preprocess, 2292.8ms inference, 14.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 banana, 2388.2ms\n",
      "Speed: 3.0ms preprocess, 2388.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s3_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 2356.5ms\n",
      "Speed: 6.5ms preprocess, 2356.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s3_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1767.8ms\n",
      "Speed: 6.4ms preprocess, 1767.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s2_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 person, 1 banana, 1363.7ms\n",
      "Speed: 2.8ms preprocess, 1363.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s5_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1450.5ms\n",
      "Speed: 3.3ms preprocess, 1450.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s2_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 kite, 1 banana, 1359.9ms\n",
      "Speed: 4.0ms preprocess, 1359.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s1_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 person, 1 banana, 1382.6ms\n",
      "Speed: 2.7ms preprocess, 1382.6ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s1_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1384.7ms\n",
      "Speed: 5.0ms preprocess, 1384.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s3_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1402.3ms\n",
      "Speed: 2.8ms preprocess, 1402.3ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s1_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1425.2ms\n",
      "Speed: 2.8ms preprocess, 1425.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s4_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1563.3ms\n",
      "Speed: 2.7ms preprocess, 1563.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s6_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1423.3ms\n",
      "Speed: 2.9ms preprocess, 1423.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s4_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 person, 1 kite, 1 banana, 1425.2ms\n",
      "Speed: 3.0ms preprocess, 1425.2ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s4_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1389.5ms\n",
      "Speed: 3.0ms preprocess, 1389.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s5_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1427.9ms\n",
      "Speed: 2.8ms preprocess, 1427.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s5_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 surfboard, 1347.4ms\n",
      "Speed: 4.2ms preprocess, 1347.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 kite, 1 banana, 1375.8ms\n",
      "Speed: 3.5ms preprocess, 1375.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s2_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1446.5ms\n",
      "Speed: 2.8ms preprocess, 1446.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "WARNING ⚠️ 'source' is missing. Using 'source=https://ultralytics.com/images/bus.jpg'.\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s6_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/nunomachado/Documents/MECD/S2/PMBA/PMBA_project/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 1454.3ms\n",
      "Speed: 2.1ms preprocess, 1454.3ms inference, 10.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 banana, 1402.2ms\n",
      "Speed: 3.7ms preprocess, 1402.2ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n5_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1364.7ms\n",
      "Speed: 4.8ms preprocess, 1364.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n4_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1399.9ms\n",
      "Speed: 5.2ms preprocess, 1399.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n5_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1416.1ms\n",
      "Speed: 3.0ms preprocess, 1416.1ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n4_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1381.6ms\n",
      "Speed: 4.6ms preprocess, 1381.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n5_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1494.2ms\n",
      "Speed: 3.5ms preprocess, 1494.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1370.9ms\n",
      "Speed: 3.6ms preprocess, 1370.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n4_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1600.7ms\n",
      "Speed: 2.9ms preprocess, 1600.7ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n5_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1414.5ms\n",
      "Speed: 2.8ms preprocess, 1414.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n1_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1380.6ms\n",
      "Speed: 2.8ms preprocess, 1380.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n1_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1410.0ms\n",
      "Speed: 2.8ms preprocess, 1410.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n4_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1359.2ms\n",
      "Speed: 2.8ms preprocess, 1359.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1368.5ms\n",
      "Speed: 4.5ms preprocess, 1368.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1394.2ms\n",
      "Speed: 3.1ms preprocess, 1394.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n1_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1413.5ms\n",
      "Speed: 2.9ms preprocess, 1413.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n2_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1524.5ms\n",
      "Speed: 3.0ms preprocess, 1524.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n2_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1396.0ms\n",
      "Speed: 2.8ms preprocess, 1396.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1392.3ms\n",
      "Speed: 2.9ms preprocess, 1392.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n2_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1400.6ms\n",
      "Speed: 3.1ms preprocess, 1400.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n1_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1397.8ms\n",
      "Speed: 3.8ms preprocess, 1397.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1394.8ms\n",
      "Speed: 4.4ms preprocess, 1394.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "WARNING ⚠️ 'source' is missing. Using 'source=https://ultralytics.com/images/bus.jpg'.\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n2_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/nunomachado/Documents/MECD/S2/PMBA/PMBA_project/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 1422.8ms\n",
      "Speed: 3.4ms preprocess, 1422.8ms inference, 11.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 banana, 1480.3ms\n",
      "Speed: 4.5ms preprocess, 1480.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n1_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1393.5ms\n",
      "Speed: 5.1ms preprocess, 1393.5ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n5_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1457.2ms\n",
      "Speed: 3.9ms preprocess, 1457.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n4_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1482.1ms\n",
      "Speed: 3.0ms preprocess, 1482.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n1_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1402.8ms\n",
      "Speed: 4.8ms preprocess, 1402.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n2_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1418.0ms\n",
      "Speed: 3.0ms preprocess, 1418.0ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n3_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1543.2ms\n",
      "Speed: 2.8ms preprocess, 1543.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n5_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1402.6ms\n",
      "Speed: 3.2ms preprocess, 1402.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n4_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1420.9ms\n",
      "Speed: 4.0ms preprocess, 1420.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n2_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1427.4ms\n",
      "Speed: 4.1ms preprocess, 1427.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n2_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1454.3ms\n",
      "Speed: 3.0ms preprocess, 1454.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n3_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1556.4ms\n",
      "Speed: 5.1ms preprocess, 1556.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n1_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1431.1ms\n",
      "Speed: 3.0ms preprocess, 1431.1ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n4_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1420.9ms\n",
      "Speed: 3.3ms preprocess, 1420.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "WARNING ⚠️ 'source' is missing. Using 'source=https://ultralytics.com/images/bus.jpg'.\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n5_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/nunomachado/Documents/MECD/S2/PMBA/PMBA_project/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 1532.8ms\n",
      "Speed: 45.3ms preprocess, 1532.8ms inference, 11.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "path_classes = [\"Green\", \"Yellowish_Green\", \"Midripen\", \"Overripen\"]\n",
    "path_folder = \"classification_cnn/nuno_nosso_dataset_cnn\"\n",
    "path_newfoler = \"classification_cnn/segcrop_nuno_nosso_dataset_cnn\"\n",
    "\n",
    "#seg_model()\n",
    "\n",
    "for rel_path_class in path_classes:\n",
    "    seg_model.predict()\n",
    "    path_class = os.path.join(path_folder, rel_path_class)\n",
    "    for rel_image_path in os.listdir(path_class):\n",
    "        image_path = os.path.join(path_class, rel_image_path)\n",
    "        if 'DS_Store' in image_path:\n",
    "            continue\n",
    "        image = plt.imread(image_path)\n",
    "        result = seg_model(image)[0]\n",
    "        boxes_classes = result.boxes.cls.numpy()\n",
    "        banana_box_idx = np.where(boxes_classes == 46.)[0]\n",
    "        if banana_box_idx.size != 1:\n",
    "            continue\n",
    "        mask = np.zeros_like(image)\n",
    "        mask = cv2.drawContours(mask, [result.masks.xy[0].astype(int)], 0, (255,255,255), -1)\n",
    "        xyxy = result.boxes.xyxy[0].numpy().astype(int)\n",
    "        seg_image = mask & image\n",
    "        crop_image = seg_image[xyxy[1]:xyxy[3], xyxy[0]:xyxy[2] ]\n",
    "        newpath = os.path.join(path_newfoler, rel_path_class, rel_image_path)\n",
    "        plt.imsave(newpath, crop_image)\n",
    "        print(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset_saranya2021/Green/g001.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-157920019fb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset_saranya2021/Green/g001.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxyxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mxyxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2374\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[1;32m   1503\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset_saranya2021/Green/g001.jpg'"
     ]
    }
   ],
   "source": [
    "image = plt.imread(\"dataset_saranya2021/Green/g001.jpg\")\n",
    "result = seg_model.predict(image)[0]\n",
    "xyxy = result.boxes.xyxy[0].numpy().astype(int)\n",
    "plt.imshow(image[xyxy[1]:xyxy[3], xyxy[0]:xyxy[2] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d59734fbeb9fca37cc515a11cf6c1101fde54de1c195f7fb5593e1b9c302c936"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
