{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import functions\n",
    "import os\n",
    "\n",
    "#for detection/segmentation\n",
    "!#pip install ultralytics\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model = YOLO(\"yolov8l-seg.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ 'source' is missing. Using 'source=https://ultralytics.com/images/bus.jpg'.\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 /Users/nunomachado/Documents/MECD/S2/PMBA/PMBA_project/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 2171.7ms\n",
      "Speed: 35.1ms preprocess, 2171.7ms inference, 12.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 banana, 1410.2ms\n",
      "Speed: 7.9ms preprocess, 1410.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s3_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1496.1ms\n",
      "Speed: 3.1ms preprocess, 1496.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s3_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1410.1ms\n",
      "Speed: 5.3ms preprocess, 1410.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s2_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 person, 1 banana, 1367.2ms\n",
      "Speed: 3.2ms preprocess, 1367.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s5_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1357.5ms\n",
      "Speed: 16.9ms preprocess, 1357.5ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s2_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 kite, 1 banana, 1537.5ms\n",
      "Speed: 4.3ms preprocess, 1537.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s1_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1549.6ms\n",
      "Speed: 4.3ms preprocess, 1549.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s3_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1442.3ms\n",
      "Speed: 4.7ms preprocess, 1442.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s1_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1670.0ms\n",
      "Speed: 4.3ms preprocess, 1670.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s4_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1442.1ms\n",
      "Speed: 3.3ms preprocess, 1442.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s6_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1410.7ms\n",
      "Speed: 4.5ms preprocess, 1410.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s4_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 person, 1 kite, 1 banana, 2040.8ms\n",
      "Speed: 8.6ms preprocess, 2040.8ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s4_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 2475.2ms\n",
      "Speed: 3.0ms preprocess, 2475.2ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s5_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 2052.0ms\n",
      "Speed: 7.9ms preprocess, 2052.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s5_23.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 surfboard, 1526.0ms\n",
      "Speed: 5.7ms preprocess, 1526.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 kite, 1 banana, 1867.6ms\n",
      "Speed: 7.2ms preprocess, 1867.6ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s2_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1798.7ms\n",
      "Speed: 5.7ms preprocess, 1798.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "WARNING ⚠️ 'source' is missing. Using 'source=https://ultralytics.com/images/bus.jpg'.\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Green/s6_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/nunomachado/Documents/MECD/S2/PMBA/PMBA_project/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 1645.1ms\n",
      "Speed: 14.7ms preprocess, 1645.1ms inference, 15.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 banana, 1844.7ms\n",
      "Speed: 5.3ms preprocess, 1844.7ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n5_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1930.2ms\n",
      "Speed: 6.0ms preprocess, 1930.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n4_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1853.5ms\n",
      "Speed: 9.8ms preprocess, 1853.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n5_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 2114.3ms\n",
      "Speed: 3.0ms preprocess, 2114.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n4_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 2055.2ms\n",
      "Speed: 5.7ms preprocess, 2055.2ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n5_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1868.6ms\n",
      "Speed: 5.8ms preprocess, 1868.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 person, 1 banana, 1688.0ms\n",
      "Speed: 5.3ms preprocess, 1688.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/s1_39.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1517.9ms\n",
      "Speed: 3.7ms preprocess, 1517.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n4_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1514.4ms\n",
      "Speed: 3.0ms preprocess, 1514.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n5_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1756.6ms\n",
      "Speed: 3.4ms preprocess, 1756.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n1_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1482.1ms\n",
      "Speed: 5.1ms preprocess, 1482.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n1_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1478.4ms\n",
      "Speed: 3.6ms preprocess, 1478.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n4_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1599.6ms\n",
      "Speed: 7.4ms preprocess, 1599.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1465.7ms\n",
      "Speed: 3.9ms preprocess, 1465.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1765.5ms\n",
      "Speed: 4.5ms preprocess, 1765.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n1_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1631.4ms\n",
      "Speed: 5.2ms preprocess, 1631.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n2_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1493.7ms\n",
      "Speed: 4.4ms preprocess, 1493.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n2_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1463.7ms\n",
      "Speed: 4.0ms preprocess, 1463.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1695.2ms\n",
      "Speed: 4.3ms preprocess, 1695.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n2_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1682.7ms\n",
      "Speed: 3.2ms preprocess, 1682.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n1_81.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1478.2ms\n",
      "Speed: 7.8ms preprocess, 1478.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n3_53.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1611.2ms\n",
      "Speed: 4.1ms preprocess, 1611.2ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "WARNING ⚠️ 'source' is missing. Using 'source=https://ultralytics.com/images/bus.jpg'.\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Yellowish_Green/n2_29.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/nunomachado/Documents/MECD/S2/PMBA/PMBA_project/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 1540.3ms\n",
      "Speed: 2.6ms preprocess, 1540.3ms inference, 11.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x480 1 banana, 1505.6ms\n",
      "Speed: 6.9ms preprocess, 1505.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n1_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1715.9ms\n",
      "Speed: 3.9ms preprocess, 1715.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n5_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1533.4ms\n",
      "Speed: 8.2ms preprocess, 1533.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n4_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1531.9ms\n",
      "Speed: 3.5ms preprocess, 1531.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n1_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1708.3ms\n",
      "Speed: 4.3ms preprocess, 1708.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n2_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1539.8ms\n",
      "Speed: 4.3ms preprocess, 1539.8ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n3_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1613.8ms\n",
      "Speed: 4.2ms preprocess, 1613.8ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n5_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1603.1ms\n",
      "Speed: 5.1ms preprocess, 1603.1ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n4_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1566.8ms\n",
      "Speed: 5.2ms preprocess, 1566.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n2_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1554.0ms\n",
      "Speed: 7.3ms preprocess, 1554.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n2_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1620.2ms\n",
      "Speed: 6.6ms preprocess, 1620.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n3_125.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 640x480 1 banana, 1622.3ms\n",
      "Speed: 3.5ms preprocess, 1622.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n1_141.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1503.0ms\n",
      "Speed: 3.5ms preprocess, 1503.0ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n4_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 banana, 1635.3ms\n",
      "Speed: 5.4ms preprocess, 1635.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "WARNING ⚠️ 'source' is missing. Using 'source=https://ultralytics.com/images/bus.jpg'.\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_cnn/segcrop_nuno_nosso_dataset_cnn/Midripen/n5_102.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1 /Users/nunomachado/Documents/MECD/S2/PMBA/PMBA_project/bus.jpg: 640x480 5 persons, 1 bus, 1 stop sign, 1 tie, 1601.5ms\n",
      "Speed: 15.3ms preprocess, 1601.5ms inference, 13.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "path_classes = [\"Green\", \"Yellowish_Green\", \"Midripen\", \"Overripen\"]\n",
    "path_folder = \"classification_cnn/nuno_nosso_dataset_cnn\"\n",
    "path_newfoler = \"classification_cnn/segcrop_nuno_nosso_dataset_cnn\"\n",
    "\n",
    "#seg_model()\n",
    "\n",
    "for rel_path_class in path_classes:\n",
    "    seg_model.predict()\n",
    "    path_class = os.path.join(path_folder, rel_path_class)\n",
    "    for rel_image_path in os.listdir(path_class):\n",
    "        image_path = os.path.join(path_class, rel_image_path)\n",
    "        if 'DS_Store' in image_path:\n",
    "            continue\n",
    "        image = plt.imread(image_path)\n",
    "        result = seg_model(image)[0]\n",
    "        boxes_classes = result.boxes.cls.numpy()\n",
    "        banana_box_idx = np.where(boxes_classes == 46.)[0]\n",
    "        if banana_box_idx.size != 1:\n",
    "            continue\n",
    "        mask = np.zeros_like(image)\n",
    "        mask = cv2.drawContours(mask, [result.masks.xy[0].astype(int)], 0, (255,255,255), -1)\n",
    "        xyxy = result.boxes.xyxy[0].numpy().astype(int)\n",
    "        seg_image = mask & image\n",
    "        crop_image = seg_image[xyxy[1]:xyxy[3], xyxy[0]:xyxy[2] ]\n",
    "        newpath = os.path.join(path_newfoler, rel_path_class, rel_image_path)\n",
    "        plt.imsave(newpath, crop_image)\n",
    "        print(newpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = plt.imread(\"dataset_saranya2021/Green/g001.jpg\")\n",
    "result = seg_model.predict(image)[0]\n",
    "xyxy = result.boxes.xyxy[0].numpy().astype(int)\n",
    "plt.imshow(image[xyxy[1]:xyxy[3], xyxy[0]:xyxy[2] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d59734fbeb9fca37cc515a11cf6c1101fde54de1c195f7fb5593e1b9c302c936"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
